

def fit_model_split_amb_unamb_gain_loss(trial_table,cross_validate=False,combined=True,split_gain_loss=True,whichreturn='ambig_gain',params=[],zscore=True):


    # select trials
    if whichreturn=='ambig_gain':
        # ambig gain
        tt = trial_table.copy()
        amb = (tt['ambig_l']==1) | (tt['ambig_r']==1)
        tt = tt.loc[(tt['gain_or_loss_trial']=='gain')&(amb),]
        task = 'gain'
        y = tt['resp_amb_1'].as_matrix()

    elif whichreturn=='ambig_loss':
        tt = trial_table.copy()
        amb = (tt['ambig_l']==1) | (tt['ambig_r']==1)
        tt = tt.loc[(tt['gain_or_loss_trial']=='loss')&(amb),]
        task='loss'
        y = tt['resp_amb_1'].as_matrix()

    elif whichreturn=='ambig_shock':
        tt=trial_table.copy()
        task='shock'
        amb = (tt['ambig_l']==1) | (tt['ambig_r']==1)
        tt = tt.loc[(tt['gain_or_loss_trial']==task)&(amb),]
        y = tt['resp_amb_1'].as_matrix()

    elif whichreturn=='unambig_gain':
        # ambig gain
        tt = trial_table.copy()
        amb = (tt['ambig_l']==0) & (tt['ambig_r']==0)
        tt = tt.loc[(tt['gain_or_loss_trial']=='gain')&(amb),]
        task = 'gain'
        y = tt['resp_r_1'].as_matrix()

    elif whichreturn=='unambig_loss':
        # ambig gain
        tt = trial_table.copy()
        amb = (tt['ambig_l']==0) & (tt['ambig_r']==0)
        tt = tt.loc[(tt['gain_or_loss_trial']=='loss')&(amb),]
        task = 'loss'
        y = tt['resp_r_1'].as_matrix()
    elif whichreturn=='unambig_shock':
        tt = trial_table.copy()
        amb = (tt['ambig_l']==0) & (tt['ambig_r']==0)
        task = 'shock'
        tt = tt.loc[(tt['gain_or_loss_trial']==task)&(amb),]
        y = tt['resp_r_1'].as_matrix()

    X = pd.DataFrame(data=np.ones(len(tt)),columns=['intercept'])
    # choose regressors

    if 'evdiff' in params:
        if whichreturn=='ambig_gain' or whichreturn=='ambig_loss' or whichreturn=='ambig_shock':
            X['evdiff_amb_'+task]=(tt['mag_ambig']-tt['mag_unambig']).as_matrix()*(tt['prob_o_ambig_bayes']-tt['prob_o_unambig']).as_matrix()
        if whichreturn=='unambig_gain' or whichreturn=='unambig_loss':
            raise ValueError('Chris: not implemented')
            #X['evdiff_rl_'+task]=(tt['mag_right']-tt['mag_left']).as_matrix()

    if 'mag_amb' in params:
        if whichreturn=='ambig_gain' or whichreturn=='ambig_loss' or whichreturn=='ambig_shock':
            X['mag_ambig_'+task]=tt['mag_ambig'].as_matrix()
            X['mag_unambig_'+task]=tt['mag_unambig'].as_matrix()

    if 'prob_amb' in params:
        if whichreturn=='ambig_gain' or whichreturn=='ambig_loss' or whichreturn=='ambig_shock':
            X['prob_ambig_'+task]=tt['prob_o_ambig_bayes'].as_matrix()
            X['prob_unambig_'+task]=tt['prob_o_unambig'].as_matrix()

    if 'mag_diff' in params:
        if whichreturn=='ambig_gain' or whichreturn=='ambig_loss' or whichreturn=='ambig_shock':
            X['mag_diff_amb_'+task]=(tt['mag_ambig']-tt['mag_unambig']).as_matrix()
        if whichreturn=='unambig_gain' or whichreturn=='unambig_loss' or whichreturn=='unambig_shock':
            X['mag_diff_rl_'+task]=tt['mag_right'].as_matrix()-tt['mag_left'].as_matrix()

    if 'prob_diff_nonbayes' in params:
        if whichreturn=='ambig_gain' or whichreturn=='ambig_loss' or whichreturn=='ambig_shock':
            X['prob_diff_nonbayes_amb_'+task]=(tt['prob_o_ambig']-tt['prob_o_unambig']).as_matrix()

    if 'prob_diff' in params:
        if whichreturn=='ambig_gain' or whichreturn=='ambig_loss' or whichreturn=='ambig_shock':
            X['prob_diff_amb_'+task]=(tt['prob_o_ambig_bayes']-tt['prob_o_unambig']).as_matrix()
        if whichreturn=='unambig_gain' or whichreturn=='unambig_loss' or whichreturn=='unambig_shock':
            X['prob_diff_rl_'+task]=(tt['prob_o_r']-tt['prob_o_l']).as_matrix()

    if 'log_prob_diff' in params:
        if whichreturn=='ambig_gain' or whichreturn=='ambig_loss' or whichreturn=='ambig_shock':
            diff = (tt['prob_o_ambig_bayes'].as_matrix()-tt['prob_o_unambig'].as_matrix())
            sign = np.sign(diff)
            X['log_prob_diff_amb_'+task]=sign*(np.log(np.abs(diff)+1.0))
        if whichreturn=='unambig_gain' or whichreturn=='unambig_loss' or whichreturn=='unambig_shock':
            diff = (tt['prob_o_r'].as_matrix()-tt['prob_o_l'].as_matrix())
            sign = np.sign(diff)
            X['log_prob_diff_rl_'+task]=sign*(np.log(np.abs(diff)+1.0))



    if 'prob_ambig' in params:
        X['prob_ambig_'+task]=tt['prob_o_ambig_bayes']

    if 'prob_unambig' in params:
        X['prob_unambig_'+task]=(tt['prob_o_unambig']).as_matrix()

    if 'mag_ambig' in params:
        X['mag_amb_'+task]=tt['mag_ambig']
        X['mag_unambig_'+task]=(tt['mag_unambig']).as_matrix()

    if 'mag_total' in params:
        X['mag_total_'+task]=(tt['mag_ambig']+tt['mag_unambig']).as_matrix()

    if 'prob_total' in params:
        X['prob_total_'+task]=(tt['prob_o_ambig_bayes']+tt['prob_o_unambig']).as_matrix()

    if 'sqrt_prop_revealed' in params:
        X['sqrt_prop_revealed_'+task]=(tt['info_amb_sqrt']).as_matrix()

    # posterior alpha, beta
    alpha = tt['revealed_o_ambig'].as_matrix().astype('float')+1
    beta = tt['revealed_x_ambig'].as_matrix().astype('float')+1 # +1 is for uniform prior

    if 'var' in params:
        var = (alpha*beta)/((alpha+beta)**2*(alpha+beta+1))
        X['var_'+task] = var

    if 'p_greater' in params:
        prob_unamb = tt['prob_o_unambig'].as_matrix()
        p_s = np.arange(0,1,0.01) # possible p to integrate over
        prob_amb_greater_than_unambig = np.empty(len(alpha))
        for pi,_ in enumerate(prob_amb_greater_than_unambig):
            post =stats.beta.pdf(p_s,alpha[pi],beta[pi])
            post = post/np.sum(post) # normalize
            prob_amb_greater_than_unambig[pi] = np.sum(post[p_s>prob_unamb[pi]])
        X['p_greater_'+task]=prob_amb_greater_than_unambig

    ### Interaction ####

    if 'inter_prob_diff_sqrt_prop_revealed' in params:
            prop_revealed = X['sqrt_prop_revealed_'+task].copy()
            prob_diff = X['prob_diff_amb_'+task].copy()
            # mean centering (liklihood stays the same, but interactions are easier to interpret)
            #prop_revealed  = (prop_revealed  -  prop_revealed.mean())/prop_revealed.std() # mean center - so the prob is relative to 0.5 # / prob_unambig .std(ddof=0) # z-score -
            #prob_diff  = (prob_diff  -  prob_diff.mean())/prob_diff.std() # mean center - so the prob is relative to 0.5 # / prob_unambig .std(ddof=0) # z-score -
            X['inter_prob_diff_sqrt_prop_revealed'] = (prop_revealed*prob_diff).as_matrix()

    if 'inter_mag_diff_sqrt_prop_revealed' in params:
            prop_revealed = X['sqrt_prop_revealed_'+task].copy()
            mag_diff = X['mag_diff_amb_'+task].copy()
            X['inter_mag_diff_sqrt_prop_revealed'] = (prop_revealed*mag_diff).as_matrix()

    if 'inter_prob_total_sqrt_prop_revealed' in params:
            prop_revealed = X['sqrt_prop_revealed_'+task].copy()
            prob_total = X['prob_total_'+task].copy()
            X['inter_prob_total_sqrt_prop_revealed'] = (prop_revealed*prob_total).as_matrix()

    if 'inter_mag_total_sqrt_prop_revealed' in params:
            prop_revealed = X['sqrt_prop_revealed_'+task].copy()
            X['mag_total_'+task]=tt['mag_ambig']+tt['mag_unambig']
            mag_total = X['mag_total_'+task].copy()
            X['inter_mag_total_sqrt_prop_revealed'] = (prop_revealed*mag_total).as_matrix()

    if 'inter_prob_total_prob_diff_sqrt_prop_revealed' in params:
            prop_revealed = X['sqrt_prop_revealed_'+task].copy()
            prob_total = X['prob_total_'+task].copy()
            prob_diff = X['prob_diff_amb_'+task].copy()
            X['inter_prob_total_prob_diff_sqrt_prop_revealed'] = (prop_revealed*prob_total*prob_diff).as_matrix()

    if 'inter_prob_ambig_sqrt_prop_revealed' in params:
            prop_revealed = X['sqrt_prop_revealed_'+task].copy()
            prob_amb = tt['prob_o_ambig_bayes'].as_matrix()
            X['inter_prob_ambig_sqrt_prop_revealed'] = (prop_revealed*prob_amb).as_matrix()

    if 'inter_prob_unambig_sqrt_prop_revealed' in params:
            prop_revealed = X['sqrt_prop_revealed_'+task].copy()
            prob_unamb = tt['prob_o_unambig'].as_matrix()
            X['inter_prob_unambig_sqrt_prop_revealed'] = (prop_revealed*prob_unamb).as_matrix()


    X,y = preprocess_model(X,y,zscore=zscore)
    if 'trial_number' in X.columns:
        X = X.drop('trial_number',axis=1)
    #Tracer()()


    results = sm.Logit(y,X).fit(disp=False)

    yhat = results.predict(X)
    BIC,AIC,pR2,pred_acc,AICc,AICf = calc_model_fit(y,yhat,X.shape[1],X.shape[0])

    # return
    out={}
    out['modelname']='model_split_'+whichreturn+'_'.join(params)
    out['results']=results
    out['X'] = X
    out['pseudoR2'] = pR2
    out['bic']=BIC
    out['aic']=AIC
    out['aicc']=AICc
    out['aicf']=AICf
    out['y']=y
    out['pred_y']=yhat
    out['MID']=trial_table.MID[0]
    out['params']=results.params
    out['pvalues']=results.pvalues
    out['pred_acc']=pred_acc
    return(out)
